{"name":"Scrala","tagline":"Scala crawler(spider) framework, inspired by scrapy","body":"# scrala\r\n\r\n[![Codacy Badge](https://api.codacy.com/project/badge/grade/563bbcd12d874610bca7313abe6e6fdd)](https://www.codacy.com/app/gaocegege/scrala)\r\n[![Build Status](https://travis-ci.org/gaocegege/scrala.svg?branch=master)](https://travis-ci.org/gaocegege/scrala)\r\n![License](https://img.shields.io/pypi/l/Django.svg)\r\n[![scrala published](https://jitpack.io/v/gaocegege/scrala.svg)](https://jitpack.io/#gaocegege/scrala)\r\n[![Docker Supported](https://img.shields.io/badge/docker-supported-blue.svg)](https://hub.docker.com/r/gaocegege/scrala/)\r\n[![Join the chat at https://gitter.im/gaocegege/scrala](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/gaocegege/scrala?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\r\n\r\nscrala is a web crawling framework for scala, which is inspired by [scrapy](https://github.com/scrapy/scrapy).\r\n\r\n## install\r\n\r\n### the docker way\r\n\r\n[![](https://badge.imagelayers.io/gaocegege/scrala:latest.svg)](https://imagelayers.io/?images=gaocegege/scrala:latest 'Get your own badge on imagelayers.io')\r\n\r\n[gaocegege/scrala in dockerhub](https://hub.docker.com/r/gaocegege/scrala/)\r\n\r\n#### Create a Dockerfile in your project.\r\n\r\n```\r\nFROM gaocegege/scrala:latest\r\n\r\n// COPY the build.sbt and the src to the container\r\n```\r\n\r\n#### Run a single command in docker\r\n\r\n```\r\ndocker run -v <your src>:/app/src -v <your ivy2 directory>:/root/.ivy2  gaocegege/scrala\r\n```\r\n\r\n### the sbt way\r\n\r\n**Step 1.** Add it in your build.sbt at the end of resolvers:\r\n\r\n\tresolvers += \"jitpack\" at \"https://jitpack.io\"\r\n\r\n**Step 2.** Add the dependency\r\n\r\n\tlibraryDependencies += \"com.github.gaocegege\" % \"scrala\" % \"0.1.5\"\r\n\r\n### normal way\r\n\r\n\tgit clone https://github.com/gaocegege/scrala.git\r\n\tcd ./scrala\r\n\tsbt assembly\r\n\r\nYou will get the jar in `./target/scala-<version>/`.\r\n\r\n## example\r\n\r\n\timport com.gaocegege.scrala.core.spider.impl.DefaultSpider\r\n\timport com.gaocegege.scrala.core.common.response.Response\r\n\timport java.io.BufferedReader\r\n\timport java.io.InputStreamReader\r\n\timport com.gaocegege.scrala.core.common.response.impl.HttpResponse\r\n\timport com.gaocegege.scrala.core.common.response.impl.HttpResponse\r\n\r\n\tclass TestSpider extends DefaultSpider {\r\n\t  def startUrl = List[String](\"http://www.gaocegege.com/resume\")\r\n\r\n\t  def parse(response: HttpResponse): Unit = {\r\n\t    val links = (response getContentParser) select (\"a\")\r\n\t    for (i <- 0 to links.size() - 1) {\r\n\t      request(((links get (i)) attr (\"href\")), printIt)\r\n\t    }\r\n\t  }\r\n\r\n\t  def printIt(response: HttpResponse): Unit = {\r\n\t    println((response getContentParser) title)\r\n\t  }\r\n\t}\r\n\r\n\tobject Main {\r\n\t  def main(args: Array[String]) {\r\n\t    val test = new TestSpider\r\n\t    test begin\r\n\t  }\r\n\t}\r\n\r\n\r\nJust like the scrapy, what you need to do is define a `startUrl` to tell me where to start, and override `parse(...)` to parse the response of the startUrl. And `request(...)` function is like `yield scrapy.Request(...)` in scrapy.\r\n\r\nYou can get the example project in the `./example/`\r\n\r\n## for developer\r\n\r\n### roadmap\r\n\r\nNext version is 0.2, which is also a dev version\r\n\r\n1. keep the log output simple and stupid\r\n2. add tests to keep the multi thread downloader high performance \r\n3. add new feature: rules in the spider\r\n","google":"UA-54253120-3","note":"Don't delete this file! It's used internally to help with page regeneration."}